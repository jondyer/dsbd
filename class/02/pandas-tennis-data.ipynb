{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to the Data Science pipeline\n",
    "### Analyzing the tennis data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Structure of the data file\n",
    "\n",
    "Open the file `tennis-data.txt` in an editor and peruse its contents. \n",
    "\n",
    "You will see and initial set of lines providing meta-information about the data,  then 14 lines of actual data (observations), and finally a few additional lines of text information.  The structure of the file is:\n",
    "\n",
    "```\n",
    "header\n",
    "data\n",
    "footer\n",
    "```\n",
    "\n",
    "The columns in the data are separated by white space.  Pandas provides functions for reading data in a very wide range of formats, skipping header and footer lines, transforming data types (e.g., string dates of the form 2017-01-25 to actual data types) etc.\n",
    "\n",
    "#### Possible Questions\n",
    "\n",
    "The data science pipeline is of the form:\n",
    "\n",
    "```\n",
    "Questions -> Wrangling -> Exploration -> Modeling -> Communication\n",
    "```\n",
    "Pandas can help us with the wrangling, exploration stages, and communication stages.  It also helps to set up data structures needed for the modeling phase.\n",
    "\n",
    "Given the simplicity of the tennis data set, there are not many descriptive statisitical questions we can ask.  But, some questions could be:\n",
    "\n",
    "- What is the prior probability of playing tennis?\n",
    "- Produce a frquency count for the various categories in each feature?\n",
    "- When the outlook is sunny is the temperature always hot?\n",
    "\n",
    "Think of a few more ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data set with `read_table` and use the NBs support for interactive exploration to examine named (keyword) parameters.  Used the methods `.head()` and `.tail()` to ensure that only the data lines (observations) are read and the header/footer lines are skipped.\n",
    "\n",
    "You will find it convenient to use `skiprows` in conjunction with `.head()` and `skipfooter` in conjunction `.tail()`.  I have given the needed values of 5 and 10 below.  I recommend you make these 0 and then experiment with `.head` and `.tail`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_table('tennis-data.txt', sep='\\s+', engine='python', \n",
    "                   skiprows=5,skipfooter=10)\n",
    "#df.head()\n",
    "#df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check to see if all of the observations have been read by determining the length of the data frame, which should be 14."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### .dtypes, .info, .describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get high level information about a dataframe with a few methods. `.dtypes` gives us the datatypes of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.info()` gives us few more details (number of non-null objects etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.describe()` gives us more stats.  The information returned by `describe` varies based on whether the column has numerical data or not.  The tennis data set only has non-numerical data (strings):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### labels, index, columns, values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rows of a data frame are identified by _labels_.  Unlike, the primary keys of a database table, labels need not be unique.  The columns of a data frame are also identified by labels.  The sequence of labels used to identify all the rows is known as the **index** and the sequence of labels used to identify the columns is known as **columns** :-).  The labels of the index and the columns will be shown in bold in the NB.\n",
    "\n",
    "By default, pandas sets the row labels (index) to be a sequence of integers from 0 and the column labels to be the first row of data.  Hence we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We usually want to give more meaningful names to row labels.  We can change the index of a dataframe with the method `set_index`.  Keep in mind that most operations on data frames do not change the data frame.  Rather a new one is created.  Sometime we re-assign the new data frame to the existing variable (as below) and sometimes we assign it to a new variable so that we have access to both data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('day')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we now ask for the index we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can change the index to any column we want with `set_index`, but in doing so we loose the existing index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('playtennis').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But as is the case most of the time, `set_index` also creates a new data frame i.e., the original data frame df is not changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to go back to the default index of a sequence of numbers we use `reset_index`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = df.head()\n",
    "d2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2.reset_index().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### .values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also extra the values of a data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this **rarely** done in practice --- we work with the values of a data frame when they are IN the data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving columns of a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can ask for a single column by specifying the column label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['playtennis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single column of a data frame is a data structure known as a **Series** object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = df['playtennis']\n",
    "type(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A series object can be created on its own.  For now, we will form series objects from columns of a data frame.  The index of a series is the same index of the data frame it is part of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract all the values of a series into a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract more than one column from a data frame to create  \"sub data frame\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['outlook', 'playtennis']\n",
    "df[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, we DON'T store the col names in a variable and use that to extract.  Rather we directly specify the list of column names.  The resultant double `[[...]]` may initially appear unusual, but one gets used to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['outlook','playtennis']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that with this double bracket notation if we specify only 1 column name we get a data frame with one column NOT a series. Ensure you understand the difference between `df['playtennis']` and `df[['playtennis']]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['playtennis']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving rows of a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We retrieve rows by using one of two methods `.loc[]` and `.iloc[]`.  We use `.loc` in conjunction with row labels.  Here are the first 5 rows of the data frame again: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we extrac a single row, we get a series.  `loc` (and `iloc`) are indexers where we use square brackets and NOT parenthesis (which we would use if they were functions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.loc['d4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we extract multiple rows, we get a data frame.  Note that again we specify the labels in an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.loc[['d2','d8','d11']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the usual range indexing, except that now the end label is included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['d3':'d9']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iloc` does indexing by position as opposed to labels.  Positions are 0 based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do range indexing.  But this time the end value is NOT included:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0:4]  # will give us the 0th, 1st, 2nd, and 3rd rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### value_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know how to extract columns and rows of a data frame, lets return to the series data type.  We often want to do a frequency count of the values of a series.  Suppose we want to count the number of `yes` and `no`s in the playtennis column, we could do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s=df['playtennis']\n",
    "s.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the result of `value_counts` is itself a series!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = s.value_counts()\n",
    "type(s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the relative frequency of `yes` in the whole data set by counting the total number of `yes` and dividing by the total number of entries in the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.value_counts().loc['yes']/len(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above expression could be broken into pieces as below, but the above is more idiomatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnts = s.value_counts()\n",
    "cnts.loc['yes']/len(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compute the relative frequency of both `yes` and `no` with the below.  Recall the notion of **broadcasting**: when a series is operated on by a scalar, all values in the series are operated on (there is an implicit loop)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s.value_counts()/len(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boolean Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following boolean expression.  Due to broadcasting we get a series of `True` / `False` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['outlook'] == 'sunny'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can store this series of `True`/`False` values and use it to index a data frame.  We then get those rows for which the boolean mask is `True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boolean_mask = df['outlook'] == 'sunny'\n",
    "df[boolean_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pandorable way of doing this is NOT to explicitly store the boolean mask but rather to use it inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = df[df['outlook'] == 'sunny']\n",
    "d2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like other operations `drop` is not a destructive operation.  It returns a new data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('d2')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('d2').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can drop multiple rows by specifying the labels in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d1 = df.drop(['d10', 'd12', 'd14'])\n",
    "d1.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to drop a column, we need to specify an **axis**.  You can think of a data frame with the (0,0) coordinate in the upper left.  axis=0 moves downwards and axis=1 moves to the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.drop('wind', axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is in the spirit of a list comprehension:  when we want to apply a function to a single series or all the columns of a data frame we use `apply`\n",
    "\n",
    "First, lets see how it works on a series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = df['playtennis']\n",
    "s.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us up case all the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.apply(lambda v: v.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we apply a function to a data frame the argument to that function is a series.  Hence it doesn't make sense to do\n",
    "\n",
    "```\n",
    "df.apply(lambda x: x.upper())\n",
    "```\n",
    "because at this point `x` is a series.\n",
    "\n",
    "Rather we need to `apply` a function that can be applied to series like `count`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(lambda ser: ser.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw earlier, when `describe` is applied to a series, we get another series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we apply `describe` to a data frame it is applied to each column of the data frame (which are series objects).  The resultant collection of series objects are then assembled back into a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.apply(lambda ser: ser.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets hand create a couple of series with different but overlapping indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pd.Series([80, 70, 90], index='abe bob cathy'.split())\n",
    "s1\n",
    "s2 = pd.Series([10, 20, 30], index='bob don abe'.split())\n",
    "\n",
    "print(s1)\n",
    "print()\n",
    "print(s2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to broad casting, when we perform an operation on a series at a whole, all of the values in the series are operated on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(s1+5)*10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can join two series together with `append`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s1.append(s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something interesting happens when we do an entry by entry operation on a series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1+s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas automatically aligns row labels and performs the operation only on those rows.  The rest are deemed \"Not a Number\" `NaN`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the `GROUP BY` clause of SQL, Pandas supports the ability to group rows in a number of ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grps = df.groupby('playtennis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`grps` has a data type of its own.  Its constituent parts are data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(grps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get information on the groups and their constituent rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grps.groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of each group is available as a series object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grps.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the individual data frames in a group with `.get_group`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grps.get_group('no')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also iterate across all the groups in a grougby object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,g in grps:\n",
    "    print(k)\n",
    "    print(g)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate them with a list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=[(k,g) for (k,g) in grps]\n",
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(lst[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### .apply on groupby objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also apply a function to a grouby object.  In this instance the function that is applied takes a data frame as the argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grps.apply(lambda d: len(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets spend some time dissecting the below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.apply(lambda s: s.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blend individual data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### .agg or .aggregating values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`agg` is similar to `apply` but differs in the following crucial ways.\n",
    "\n",
    "   [1] `apply` can be used with a series, dataframe or group.  The function being applied takes the components of the data type to which it is applied:\n",
    "   \n",
    "   ```Something.apply(lambda x: ______ )\n",
    "   ```\n",
    "   \n",
    "   If `Something` is \n",
    "       - a series then x is a value\n",
    "       - a data frame then x is a column (series)\n",
    "       - a group then x is a data frame\n",
    "       \n",
    "       \n",
    "   [2] `agg` can only be applied to a group and the function is applied to each column of the data frames in the group i.e., x is a series.  Also, multiple functions can be used during aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grps.get_group('no').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(grps.get_group('no'))+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grps.agg(['count', lambda s: len(s)+10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(s):\n",
    "    return len(s)+100\n",
    "\n",
    "grps.agg(['count', f])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
